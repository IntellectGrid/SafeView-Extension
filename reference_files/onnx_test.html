<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>ONNX Runtime Test</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
</head>
<body>
    <h1>ONNX Runtime Test - EfficientNet-B0 NSFW Classifier</h1>
    <p>This page tests the ONNX model loading and inference outside the extension context.</p>
    
    <label>Select an image: <input type="file" id="imageInput" accept="image/*"></label>
    <br><br>
    <canvas id="canvas" width="224" height="224" style="border: 1px solid #ccc;"></canvas>
    <br><br>
    <button id="runInference">Run Inference</button>
    <pre id="output"></pre>

    <script>
        const CLASSES = ['Drawing', 'Hentai', 'Neutral', 'Porn', 'Sexy'];
        const INPUT_SIZE = 224;
        const MEAN = [0.485, 0.456, 0.406];
        const STD = [0.229, 0.224, 0.225];
        
        let session = null;
        let currentImage = null;

        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const output = document.getElementById('output');

        // Load model on page load
        (async () => {
            output.textContent = 'Loading ONNX model...';
            try {
                // Update this path to point to your ONNX file
                // For testing, you'll need to serve this HTML from the extension root or adjust path
                session = await ort.InferenceSession.create('../src/assets/models/efficientnetb0/efficientnet_b0.onnx');
                output.textContent = 'Model loaded successfully!\nSelect an image and click "Run Inference".';
            } catch (e) {
                output.textContent = 'Error loading model: ' + e.message;
                console.error(e);
            }
        })();

        document.getElementById('imageInput').addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (!file) return;
            const reader = new FileReader();
            reader.onload = (ev) => {
                const img = new Image();
                img.onload = () => {
                    currentImage = img;
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                    ctx.drawImage(img, 0, 0, INPUT_SIZE, INPUT_SIZE);
                    output.textContent = 'Image loaded. Click "Run Inference" to classify.';
                };
                img.src = ev.target.result;
            };
            reader.readAsDataURL(file);
        });

        document.getElementById('runInference').addEventListener('click', async () => {
            if (!session) {
                output.textContent = 'Model not loaded yet.';
                return;
            }
            if (!currentImage) {
                output.textContent = 'Please select an image first.';
                return;
            }

            output.textContent = 'Running inference...';

            try {
                const imageData = ctx.getImageData(0, 0, INPUT_SIZE, INPUT_SIZE);
                const data = imageData.data;

                // Preprocess to CHW float32 normalized
                const floatData = new Float32Array(3 * INPUT_SIZE * INPUT_SIZE);
                let ptr = 0;
                for (let c = 0; c < 3; c++) {
                    for (let y = 0; y < INPUT_SIZE; y++) {
                        for (let x = 0; x < INPUT_SIZE; x++) {
                            const idx = (y * INPUT_SIZE + x) * 4;
                            let value = data[idx + c] / 255.0;
                            value = (value - MEAN[c]) / STD[c];
                            floatData[ptr++] = value;
                        }
                    }
                }

                const tensor = new ort.Tensor('float32', floatData, [1, 3, INPUT_SIZE, INPUT_SIZE]);
                const feeds = { input: tensor };
                const results = await session.run(feeds);
                const logits = Array.from(results.output.data);

                // Softmax
                const expScores = logits.map(Math.exp);
                const sum = expScores.reduce((a, b) => a + b, 0);
                const probs = expScores.map(x => x / sum);

                let resultText = 'Predictions:\n';
                CLASSES.forEach((cls, i) => {
                    resultText += `${cls}: ${(probs[i] * 100).toFixed(2)}%\n`;
                });

                output.textContent = resultText;
            } catch (e) {
                output.textContent = 'Inference error: ' + e.message;
                console.error(e);
            }
        });
    </script>
</body>
</html>
